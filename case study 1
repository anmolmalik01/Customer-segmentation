Advancing Customer Segmentation: A Comparative Study of Hierarchical Level Weighted Method and K-Means Algorithms

								Abstract

This paper delves into the crucial aspect of customer segmentation and its significance in understanding consumer behavior for businesses. Customer segmentation involves dividing customers into distinct groups based on common characteristics, behaviors, and preferences. The study explores the application of a weighted approach and clustering techniques in the customer segmentation process.

The supermarket dataset used in this research comprises transactional data from a supermarket, encompassing details such as date, time, products purchased, individual product prices, and the total transaction amount. Leveraging this dataset, data analysis techniques are employed to gain insights into supermarket customers' behavior. For instance, the relationship between the day of the week and total transaction amounts is studied, factors influencing customer spending patterns are analyzed, and trends in customer behavior are identified.


This project focuses on customer segmentation utilizing two distinct approaches: K-means clustering and a weighted method. The first approach involves employing K-means clustering to segment customers based on their characteristics. The second approach utilizes a weighted method, assigning varying importance to specific attributes for enhanced segmentation. The project leverages these two approaches on a dataset to gain valuable insights into customer behavior and preferences. By exploring these techniques, businesses can tailor marketing strategies effectively, improve customer engagement, and optimize overall performance for success.


Keywords: Customer Segmentation, Consumer Behavior, Weighted Approach, Clustering Techniques, Supermarket Dataset, Transactional Data, Data Analysis, Marketing Strategies, Business Performance, Practical Implications






						Introduction


In recent years, the grocery retail business has witnessed immense development, benefiting from a growing global economy. The United States Department of Agriculture (USDA) (2016) projected worldwide food retail sales of roughly $4 trillion yearly, with the Institute of Grocery Distribution (IGD) (2015) estimating a tripling of the world's grocery market value to over $12 trillion by 2020. Due to rapidly changing market landscape, businesses face intense competition and ever-evolving consumer demands. To succeed and thrive, companies must focus on improving customer satisfaction and cultivating long-term loyalty among their clientele. One effective way to achieve this is through personalized services and tailored marketing strategies that cater to individual customer needs and preferences.


Customer segmentation plays a pivotal role in this process. It involves dividing a company's customer base into distinct groups or segments based on various criteria, such as demographics, behavior, purchasing patterns, interests, and other relevant characteristics. By grouping customers with similar attributes together, businesses can gain valuable insights into the unique patterns, preferences, and behaviors within these consumer clusters.To effectively implement customer segmentation, businesses need access to comprehensive and accurate customer data. This data can be collected through various channels, such as online interactions, customer feedback, purchase history, surveys, and social media. Advanced data analytics and machine learning techniques can then be employed to identify meaningful patterns and create actionable customer segments.


Customer segmentation is a way for helping institutions to categorize their target market into distinct groups based on shared characteristics, behaviors, needs, and preferences. This process enables companies to gain deeper insights into their customers and tailor their marketing efforts and products to meet the specific requirements of each segment effectively. By applying segmentation criteria, businesses can create homogeneous and unique customer groups, allowing for more targeted marketing strategies. Through personalized experiences and focused approaches, customer satisfaction and loyalty can be improved, leading to increased sales, revenue, and a competitive edge in the market. Regular monitoring and refinement ensure that businesses adapt to changing customer preferences and stay ahead in the dynamic business landscape.  It is an indispensable tool in modern marketing and customer service strategies. This can help businesses to build stronger customer relationships, drive brand loyalty, and ultimately achieve sustainable growth amid the dynamic and competitive market landscape.Customer segmenatation can be done on these factors; demographics, Psychographics, Geographic Location, Socioeconomic Status, Buying Frequency, Purchase History. Armed with this valuable insight, businesses can then offer tailored solutions and experiences that resonate with specific customer segments, setting themselves apart from competitors who may take a one-size-fits-all approach. The increase global connectivity and improved supply chains leads to the need for customer segmentation more pronounced. These factors have brought about significant changes in the business landscape, making customer-centricity a critical aspect of remaining relevant and successful in today's competitive markets. A customer-centric approach, fueled by data-driven insights from segmentation, enables companies to deliver personalized experiences, stay ahead of market trends, and build enduring customer relationships. As businesses adapt to these dynamic market forces, customer segmentation remains a fundamental strategy for achieving relevance, success, and sustained growth.


The unprecedented volume and diversity of data available to businesses through digital channels has led to an explosion of data in today's business landscape. This data comes in various formats, including text, images, videos, transaction records, customer interactions, and more. To harness the full potential of this data, effective data management and integration are paramount. By collecting, storing, and integrating data from various sources, businesses can make data-driven decisions, and remain competitive in an increasingly digital and data-driven business landscape. However, it is essential to balance data utilization with data privacy and compliance to build and maintain trust with customers. Leveraging the wealth of available data, customer segmentation has reached new heights as businesses harness demographic, psychographic, and behavioral information to create comprehensive customer profiles. By integrating these diverse data sources, companies gain valuable insights into customer sentiment, preferences, and behaviors. Armed with this deeper understanding, businesses can design highly targeted marketing campaigns that resonate with specific customer segments, delivering personalized recommendations and experiences. The result is enhanced customer satisfaction and loyalty, as customers feel seen and understood by the brand. With data-driven segmentation, businesses can build stronger connections with their clientele, fostering long-term loyalty and sustainable growth in today's competitive market landscape.

There are many algorithms and techniques we can achieve customer segmentation, one of the most widely used methods is clustering, which includes algorithms like K-means, hierarchical clustering, and density-based clustering. K-means is known for its simplicity and efficiency in dividing customers into distinct clusters based on similarities in their attributes and behaviors. Hierarchical clustering creates a hierarchical representation of customer groups, allowing for insights at various levels of granularity. Density-based clustering, such as DBSCAN, identifies clusters based on density thresholds, accommodating irregularly shaped segments and handling noisy data efficiently. Beyond clustering, other techniques like decision trees, regression analysis, and neural networks are utilized for customer segmentation. Decision trees segment customers based on a series of binary decisions, while regression analysis helps identify significant predictors of customer behavior. Neural networks can capture complex relationships among customer attributes and create accurate segmentations. Each technique has its strengths and limitations, and businesses may employ a combination of these methods to gain a comprehensive understanding of their customer base and develop targeted marketing strategies that cater to specific customer segments.



By targeting high-value customers and offering personalized solutions, companies can optimize their marketing efforts, reduce acquisition costs, and improve customer retention rates. This, in turn, enhances the company's overall profitability and strengthens its competitive position in the market. Overall, customer segmentation empowers businesses to understand and cater to the diverse needs of their customer base, creating differentiation and competitive advantage in a crowded marketplace. By identifying and prioritizing high-value customers, companies can make smarter decisions about resource allocation, ensuring that efforts are focused on nurturing the relationships that matter most to the company's success. Through tailored solutions and personalized experiences, businesses can enhance customer satisfaction and build long-term loyalty, securing their position as market leaders in the face of intense competition.


Analyzing historical data and behavior patterns empowers businesses to predict future trends and demands, making it a vital tool in rapidly changing industries. By leveraging data-driven insights, companies can stay ahead of the curve and adapt their strategies proactively to meet evolving customer needs and market dynamics. Historical data analysis involves examining past trends, customer behaviors, and market shifts to identify patterns and correlations. By understanding what has happened in the past, businesses can gain valuable context and insights into the factors that have influenced their performance and customer interactions. This historical perspective serves as a foundation for predicting potential future scenarios. By analyzing customer behaviors, such as purchase history, browsing habits, and engagement with marketing campaigns, companies can identify emerging preferences and shifting demands. This information allows businesses to anticipate the changing needs of their customers and align their product offerings and marketing messages accordingly.

In rapidly changing industries, having the ability to foresee upcoming trends and demands is crucial. Market conditions can shift quickly due to technological advancements, changing consumer preferences, economic fluctuations, or competitive pressures. By analyzing historical data and behavior patterns, businesses can gain foresight into these shifts, enabling them to make proactive adjustments to their strategies and operations. Adapting strategies based on predictive insights helps businesses stay relevant and competitive. For instance, a retail company that notices a growing trend toward online shopping can invest more resources in enhancing its e-commerce platform and digital marketing efforts. Similarly, a technology company that identifies a surge in demand for a particular type of product can focus its research and development efforts to capitalize on the opportunity.
Predictive analytics also aids in resource optimization. By anticipating future demands, companies can allocate their resources efficiently, avoiding overproduction of products that may become less popular and ensuring they can meet the needs of a growing market segment.



We begin by thoroughly exploring the dataset through visualizations and summary statistics to gain valuable insights into its underlying patterns and characteristics. Followed by employing two distinct clustering techniques for segmentation purposes. We apply the widely used K-means clustering technique, which partitions the data into distinct clusters based on their similarities. By iteratively optimizing cluster centroids, K-means groups data points into clusters, allowing us to identify different customer segments effectively. Then we introduce a novel approach known as weighted clustering. Unlike traditional clustering, our proposed method assigns weights to specific variables, taking into account their relative importance in determining clusters. This weighted approach enables us to create more customized and granular segments, enhancing the accuracy of our clustering results. Creating visualizations of the clusters generated by both techniques to provide a clear and intuitive understanding of the customer segments. These visual representations aid in recognizing distinct patterns and relationships within the data, facilitating further analysis and decision-making. We conclude our findings and compare the results obtained from the K-means and weighted clustering methods. We highlight the advantages and limitations of each technique, providing valuable insights into their respective applications in customer segmentation. Our conclusions serve as a basis for data-driven strategies, enabling businesses to tailor their marketing efforts, optimize product offerings, and improve overall customer experiences.


The contribution of this research are:

1. Proposing an Experimental Hierarchical Level Weighted Method: This research introduces an innovative and experimental hierarchical level weighted method for performing clustering. Unlike traditional clustering techniques, this approach incorporates weighted attributes at different hierarchical levels, allowing for a more granular and customized segmentation.

2. Utilizing K-means for Customer Dataset Clustering: Another significant contribution of this research is the application of the well-established K-means algorithm to perform clustering on the customer dataset. 

3. Declaring Characteristics of Supermarket Customer Data and Extracting Useful Insights: The research extensively explores the characteristics of the supermarket customer dataset, including demographic information, purchasing behavior, and transactional patterns








							Data
							
							

The dataset is one of the historical sales of supermarket company which has recorded in 3 different branches for 3 months data. Predictive data analytics methods are easy to apply with this dataset.
The dataset is collect from kaggle(https://www.kaggle.com)
It consist of categorical and numerical columns
The goal is to perform EDA and customer segmenation
It consist of 1000 rows and 17 columns
The description of these variables is shown below: 	

						
							
The dataset used in this study comprises historical sales data from a supermarket company recorded over three months in three different branches. The dataset is sourced from Kaggle(https://www.kaggle.com). This supermarket dataset is a collection of data that provides information about the transactions that took place in a supermarket. This dataset typically includes information such as the date and time of the transaction, the products that were purchased, the price of each product, the total amount spent on the transaction, and other relevant details. This supermarket dataset is a valuable tool for understanding and predicting the behavior of supermarket customers, and for making data-driven decisions that can improve the performance of a supermarket business. The dataset comprises 1000 rows and 17 columns, providing a sizable amount of data for analysis. With a diverse range of variables, this dataset offers ample opportunities for uncovering hidden trends and patterns that can significantly impact business decisions.

These are the columns:
Invoice id: Computer generated sales slip invoice identification number
Branch: Branch of supercenter (3 branches are available identified by A, B and C).
City: Location of supercenters
Customer type: Type of customers, recorded by Members for customers using member card and Normal for without member card.
Gender: Gender type of customer
Product line: General item categorization groups - Electronic accessories, Fashion accessories, Food and beverages, Health and beauty, Home and lifestyle, Sports and travel
Unit price: Price of each product in $
Quantity: Number of products purchased by customer
Tax: 5% tax fee for customer buying
Total: Total price including tax
Date: Date of purchase (Record available from January 2019 to March 2019)
Time: Purchase time (10am to 9pm)
Payment: Payment used by customer for purchase (3 methods are available – Cash, Credit card and Ewallet)
COGS: Cost of goods sold
Gross margin percentage: Gross margin percentage
Gross income: Gross income
Rating: Customer stratification rating on their overall shopping experience (On a scale of 1 to 10)


						Litreture Review



							clustring 

Clustering is a fundamental unsupervised machine learning technique in data analysis that involves the grouping of similar data points or objects into distinct clusters. The goal of clustering is to identify inherent patterns, structures, and relationships within a dataset, without the need for predefined labels or target variables. By organizing data points into meaningful clusters based on their similarities and dissimilarities, clustering facilitates data exploration, pattern recognition, and the discovery of natural groupings within the data. In clustering, each data point is assigned to a cluster, and points within the same cluster share similar characteristics or properties, while points in different clusters exhibit dissimilar traits. The process of clustering is driven by mathematical algorithms that aim to minimize the intra-cluster distance and maximize the inter-cluster distance, ensuring that data points within the same cluster are more similar to each other than to those in other clusters.
Clustering finds wide applications in various fields, including customer segmentation, image processing, anomaly detection, and market research. It plays a pivotal role in customer segmentation, where businesses aim to divide their customer base into distinct groups based on shared characteristics, behaviors, or preferences. By leveraging clustering algorithms, businesses can tailor marketing strategies, optimize product offerings, and enhance overall customer experiences based on the unique needs of different customer segments. Clustering is a widely used technique in data analysis and plays a crucial role in customer segmentation. Researchers and practitioners have extensively employed various clustering algorithms to uncover meaningful patterns and groupings within datasets. Clustering methods, such as K-means, hierarchical clustering, and density-based clustering, have been applied to diverse domains, including marketing, retail, and e-commerce, to identify distinct customer segments based on shared attributes and behaviors.


K-means, as one of the most popular clustering algorithms, partitions data into clusters by iteratively updating centroids to minimize intra-cluster variance. Its simplicity, efficiency, and ease of implementation make it a go-to choice for many customer segmentation tasks. Hierarchical clustering, on the other hand, creates a hierarchical representation of data, revealing nested clusters at different levels of granularity. This method offers insights into both broad and fine-grained customer groups.

Density-based clustering, represented by algorithms like DBSCAN (Density-Based Spatial Clustering of Applications with Noise), identifies clusters based on density thresholds, accommodating irregularly shaped clusters and handling noisy data effectively. The flexibility of density-based clustering makes it suitable for various customer segmentation scenarios.

Advancements in clustering techniques have also led to hybrid approaches, combining multiple algorithms to capitalize on their strengths and overcome limitations. Genetic algorithms, particle swarm optimization, and neural networks have been integrated with clustering to optimize cluster formation and improve segmentation accuracy.

In customer segmentation literature, researchers have emphasized the importance of feature selection, data preprocessing, and the evaluation of clustering results using relevant metrics. They have demonstrated how clustering can significantly impact marketing strategies, personalized recommendations, and customer retention efforts. The insights obtained from clustering analyses aid businesses in developing targeted marketing campaigns, improving customer satisfaction, and fostering long-term customer loyalty.





						customer segmenattion

Customer segmentation is a crucial practice in marketing and data analysis, enabling businesses to divide their customer base into distinct groups based on shared characteristics and behaviors. Researchers have extensively explored various techniques to perform customer segmentation and have employed a wide range of clustering algorithms, such as K-means, hierarchical clustering, and density-based clustering.

K-means clustering, known for its simplicity and efficiency, partitions customers into clusters by iteratively optimizing cluster centroids. It has been widely adopted in customer segmentation due to its ease of implementation and ability to handle large datasets. Hierarchical clustering, on the other hand, creates hierarchical representations of customer groups, providing insights into both broad and fine-grained segments.

Density-based clustering algorithms, like DBSCAN, identify clusters based on density thresholds, accommodating irregularly shaped segments and effectively handling noisy data. These methods have demonstrated their effectiveness in identifying natural groupings of customers with similar preferences and purchase patterns.

Researchers have also explored hybrid approaches, combining multiple clustering techniques or integrating clustering with other machine learning methods to enhance segmentation accuracy. Genetic algorithms, particle swarm optimization, and neural networks have been integrated with clustering to optimize cluster formation and improve the quality of customer segments.

Customer segmentation research emphasizes the importance of data preprocessing, feature selection, and evaluation of clustering results using relevant metrics. The insights gained from customer segmentation analyses have a direct impact on marketing strategies, allowing businesses to tailor their campaigns, personalize product recommendations, and improve customer retention efforts.

Overall, customer segmentation continues to be a critical area of research and practice, empowering businesses to better understand their customer base and target their offerings to specific segments. As new data analysis methods emerge, customer segmentation remains a vital tool for businesses seeking to gain a competitive advantage by effectively meeting the diverse needs and preferences of their customers.




							kmeans


K-means clustering, for its simplicity and efficiency, K-means partitions data points into distinct clusters based on their similarities. Researchers have extensively explored the application of K-means in customer segmentation due to its straightforward nature and ability to handle large datasets efficiently. The algorithm's iterative process involves updating cluster centroids to minimize the intra-cluster variance, resulting in well-defined and mutually exclusive customer segments. Its interpretability allows businesses to gain valuable insights into customer behavior patterns and preferences. By identifying natural groupings of customers, K-means enables businesses to tailor marketing strategies and product offerings to specific segments. Researchers have also explored the impact of feature selection, data preprocessing, and the choice of the optimal number of clusters on the quality of segmentation results. They have demonstrated the effectiveness of K-means in generating meaningful customer segments, helping businesses gain a deeper understanding of their customer base. Moreover, advancements in K-means clustering have led to the development of hybrid and enhanced versions of the algorithm, integrating it with other optimization techniques to improve segmentation accuracy. The flexibility and versatility of K-means make it a versatile tool for customer segmentation tasks across various industries and datasets.




						weighted method
						
The weighted method is an innovative approach that has been explored in the context of customer segmentation. Unlike traditional clustering techniques, the weighted method introduces the concept of assigning weights to specific variables, allowing for a more customized and granular segmentation process. Researchers have investigated the advantages of this approach in improving the accuracy and interpretability of customer segments.

In the weighted method, certain attributes or features are assigned higher weights based on their relative importance in determining customer behavior and preferences. By incorporating these weights into the clustering process, the algorithm can focus on the most influential variables, resulting in more meaningful and informative customer segments.

The weighted method has shown promise in various domains, such as retail, e-commerce, and personalized marketing. It enables businesses to capture subtle nuances in customer preferences and identify distinct customer groups with unique characteristics. By emphasizing certain attributes, the weighted method can uncover hidden patterns and relationships that may not be apparent in traditional clustering approaches.

Researchers have also explored different strategies for determining the optimal weights, including data-driven approaches and expert-based knowledge. Additionally, hybrid approaches combining the weighted method with other clustering techniques have been proposed to further enhance segmentation accuracy.

Moreover, the weighted method provides businesses with a more fine-grained view of their customer base, allowing for targeted marketing strategies and personalized recommendations. This level of customization can lead to improved customer satisfaction and loyalty.

In conclusion, the weighted method represents a valuable and innovative approach to customer segmentation. By assigning weights to specific variables, businesses can gain deeper insights into their customer base and tailor their marketing strategies to effectively meet the diverse needs and preferences of different customer segments. As research in this area continues to evolve, the weighted method holds significant potential for optimizing customer segmentation efforts and enhancing overall business performance.





							EDA

Exploratory Data Analysis (EDA) is a fundamental step in the data analysis process, playing a crucial role in understanding and uncovering insights from raw data. It involves visually exploring, summarizing, and interpreting the dataset to gain valuable insights before applying more advanced modeling or statistical techniques. EDA provides an opportunity to grasp the overall structure of the data, detect patterns, relationships, and potential issues, and validate assumptions.
EDA helps researchers and data analysts become familiar with the dataset's characteristics, including the number of observations, variables, and their respective data types. Understanding the data's scope and limitations allows for informed decision-making throughout the analysis process.


	
Summary Statics:
The summary of the dataset provided numerical measures, such as maximum, minimum, quartiles, count, and standard deviation, to grasp its characteristics. These statistics offer insights into data distribution, central tendency, variability, and potential outliers.



checking null values:
Our data contain no null values


Tax 5% is the charge for the purchase which can be calcuted by computing 5% of the total
All values in the data are sources from invoice ID having each id uni depeData consist of  


Droping columns

During the data preprocessing phase, we performed column removal to enhance the relevance and efficiency of our analysis and clustring process. The dropped columns include Invoice ID, Date, Time, and gross margin percentage, Tax 5%, cogs.


Invoice ID: The Invoice ID column served as a unique identifier for each transaction in the dataset. However, it did not provide any relevant information about customer behavior or preferences, as it only represented a transactional reference number.

Date and Time: Our data does not include individual customer identification, these attributes lack relevance for our customer segmentation analysis. Retaining them would not contribute meaningful insights to our research objectives.

Gross Margin Percentage, COGS, Tax 5%, and Gross Income: After investigating the correlation matrix, we observed a high correlation among these variables. High correlation indicates that these columns share similar information and could potentially lead to multicollinearity issues during the analysis. Multicollinearity can affect the stability and interpretability of our results and may lead to unreliable insights. To avoid redundancy and potential bias in our analysis, we decided to drop these.





Handling categorical columns:

To use these columns in clustering algorithms effectively, they need to be converted into numerical format. Two commonly used methods for converting categorical columns into numerical form are LabelEncoder and One-Hot Encoder. By using One-Hot Encoder, we avoid introducing biases that could occur with LabelEncoder and create a more suitable representation for clustering analysis. Each binary column represents a distinct category, and the clustering algorithm can correctly interpret the categorical data without assuming any ordinal relationships. This allows us to effectively use categorical information in our clustering process and identify meaningful customer segments based on their unique preferences and behaviors. On the other hand, when visualization is the primary objective, LabelEncoder may be useful as it simplifies the representation of categorical data without creating separate binary columns for each unique value




Correlation matrix:
A correlation matrix is a powerful tool used in data analysis to explore the relationships between multiple variables in a dataset. It provides a comprehensive overview of the pairwise correlations between all pairs of attributes, allowing us to understand how the variables are related to each other. The values in the correlation matrix range from -1 to 1, where -1 indicates a perfect negative correlation, 1 indicates a perfect positive correlation, and 0 indicates no correlation between the variables



When three or more variables have a correlation value of 1 in the correlation matrix, it indicates a perfect positive linear relationship between these variables. In the context of your dataset, the variables "Total," "COGS" (Cost of Goods Sold), "Tax 5%," and "Gross Income" exhibit a perfect positive correlation with each other. This implies that they move in direct proportion to each other and have identical linear relationships.

Elaborating on this perfect positive correlation:

Total: The "Total" column represents the total amount spent by customers in a transaction at the supermarket. As expected, this value directly reflects the sum of "COGS," "Tax 5%," and "Gross Income."

The perfect positive correlation of 1 between these variables indicates that they are essentially redundant, providing the same information. Having identical linear relationships can lead to multicollinearity, a condition that may affect the stability and interpretability of statistical models. In practice, when encountering such a scenario, it is common to drop one or more of these highly correlated variables to avoid introducing bias and to simplify the analysis. The decision to drop redundant variables should be based on the research objective and the specific requirements of the analysis.





Frequency histogram:

Frequency histograms are graphical representations used to visualize the distribution of a continuous or discrete variable in a dataset. In a frequency histogram, the x-axis represents the variable's values, divided into intervals or bins, while the y-axis shows the frequency or count of occurrences of each value within those intervals.

The process of creating frequency histograms involves the following steps:

Binning: The range of values for the variable is divided into several intervals or bins. The number of bins can be chosen based on the data's range and the level of detail required in the visualization.

Counting Frequencies: The number of occurrences of each value within each bin is counted. This frequency count represents the number of data points falling into each interval.

Plotting the Histogram: The frequency counts are then plotted as bars on the histogram. Each bar's height corresponds to the number of data points falling within that particular interval.

Frequency histograms offer several benefits:

Understanding Data Distribution: Frequency histograms allow us to observe the distribution of the data. It helps identify patterns, skewness, or the presence of outliers, providing valuable insights into the underlying data structure.

Visualization of Numerical Data: Histograms provide an effective way to represent numerical data visually. They are particularly useful when dealing with large datasets, as they condense information into a compact form.

Data Exploration: Frequency histograms facilitate exploratory data analysis (EDA). By visually examining the distribution, data analysts can gain an initial understanding of the dataset, detect any irregularities, and decide on appropriate data preprocessing techniques.

Comparison of Distributions: Histograms allow easy comparison between different datasets or groups. By plotting multiple histograms on the same graph, analysts can observe differences or similarities in the distribution of various variables.

Identifying Patterns and Outliers: Histograms help identify patterns or clusters in the data, as well as the presence of outliers or extreme values that may influence the overall distribution.

Overall, frequency histograms are a powerful and versatile tool for data visualization and exploration. They play a crucial role in understanding the characteristics of a dataset, making data-driven decisions, and gaining meaningful insights from the data.





Boxplot vizulaization

	
	
	
	
	


					MODEL, TOOLS, ENVIRONMENT, TECHNOLOGY


Customer segmentation

Market basket analysis

							Methodology
						
	
	
								kmeans


K-means clustering aims to create distinct and non-overlapping clusters by grouping observations with similar characteristics together and separating those with dissimilar attributes. In this process, K-means identifies K initial points as centroids, either randomly or by selecting the first K points from the dataset. It then calculates the Euclidean distance between each data point and the identified centroids. Next, K-means assigns each data point to the closest centroid based on the calculated distances. This step forms the initial clusters. Afterward, the algorithm finds new centroids by computing the average of the data points in each cluster. This process is repeated iteratively, updating the centroids and reassigning data points until the centroids stabilize or the fixed number of iterations is reached. The primary objective of K-means clustering is to minimize the total within-cluster variation, which is the sum of the squared Euclidean distances between each observation's feature values and the corresponding centroid. By continuously updating the centroids based on data points' proximity, K-means aims to create clusters that have minimal internal variations and are well-separated from each other.[1,3,23,24,25,27]


formula

xi is an observation belonging to the cluster Ck
µk is the mean value of the points assigned to the cluster
Ck
Each observation (xi) is assigned to a given cluster such that the sum of squared (SS) distances of each observation to their assigned cluster centers (μk) is minimized. We define the total within-cluster variation as follows:

formula

The (SSwithin) measures the compactness (i.e., goodness) of the resulting clusters and we want it to be as small as possible.


The (SSwithin) measures the compactness (i.e., goodness) of the resulting clusters and we want it to be as small as possible.
In order to find the optimal number of clusters in K-means, it is recommended to choose it based on:
• The context of the problem at hand if we know that there is a specific number of groups in our data (this option is however subjective), or with any of the following three approaches:
• Elbow method (which uses the within cluster sums of squares by looking at the total within-cluster sum of square as a function of the number of clusters.
The location of a knee or elbow in the plot is usually considered as an indicator of the appropriate number of clusters),
• Average silhouette method (measures the quality of a clustering. That is, it determines how well each object lies within its cluster. A high average silhouette width indicates a good clustering),
• Gap statistic method (compares the total intra-cluster variation for different values of K with their expected values under null reference distribution of the data).


					
						The Validation of Hierarchical Clustering and K-means Clustering	
			


			
Validating the results of K-means clustering is an essential step to assess the quality and effectiveness of the clustering algorithm. Several methods can be used to validate K-means clustering results. Some of the common validation techniques include:

Within-Cluster Sum of Squares (WCSS): WCSS measures the compactness of clusters by calculating the sum of squared distances between data points and their assigned cluster centroids. Lower WCSS indicates better clustering. Elbow method can be used to determine the optimal number of clusters by plotting WCSS against the number of clusters and looking for the "elbow" point, which signifies the point where adding more clusters does not significantly reduce the WCSS.

Silhouette Score: Silhouette score measures how well-separated clusters are. It considers both the average distance of a point to its own cluster (a) and the average distance to the nearest neighboring cluster (b). Higher silhouette score (closer to 1) indicates better-defined clusters.

Calinski-Harabasz Index: This index evaluates the ratio of the between-cluster variance to the within-cluster variance. Higher Calinski-Harabasz index values indicate better-defined clusters.

Davies-Bouldin Index: This index measures the average similarity between each cluster and its most similar cluster. Lower values indicate better clustering

It's important to note that K-means is sensitive to the initial placement of centroids and may not perform well on certain types of data, such as datasets with irregular shapes or varying densities. In such cases, other clustering algorithms like hierarchical clustering, DBSCAN, or Gaussian Mixture Models might be more appropriate.

In conclusion, the validation of K-means clustering should be done using a combination of quantitative and visual methods to ensure that the clusters are meaningful and provide valuable insights for the specific problem at hand		
		
						
						
							weighted average

1. Weighted average method divides the column category into level heirarcy and will provide weight on each part of the level by caluclated the percetage of each part holded it.
2. Columns will be divided into 2 catergories one which will be the part of ladder and other which will be multiple
eg gender will be divided into male and female and will be part of lader
but quantity can be any number from 0 so it cannot be part of ladder but will be mulltiped in the end
this can be simply calcualted using quantity of unique values a column is hold

3. To calucalte the rank of the customer we will climb down the ladder and caluclate the final score. 
2. Then it rank the customer on the basis of the final score
3. Total data can be divided into desired cluster using quartiles



Advantages
It need continues update of data due to use of percanteage of the levels part 


Disadvantages:
Weightes can be 
  

							Conclusion
							
			
		

							References
							
							
[1] James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. An Introduction to Statistical Learning: With Applications in R. Springer.

[3] Brett Lantz. 2019. Machine Learning with R. Packt Publishing Ltd.
[6] Tavakoli, Mohammadreza, et al. “Customer Segmentation and Strategy Development Based on User Behavior Analysis, RFM Model and Data Mining Techniques: A Case Study.” 2018 IEEE 15th International Conference on E-Business Engineering (ICEBE), 2018, https://doi.org/10.1109/icebe.2018.00027.

[7] Alloghani, Mohamed, et al. “A Systematic Review on Supervised and Unsupervised Machine Learning Algorithms for Data Science.” Unsupervised and Semi-Supervised Learning, 2019, pp. 3–21, https://doi.org/10.1007/978-3-030-22475-2_1. 

[8] Han, Shui Hua, et al. “Segmentation of Telecom Customers Based on Customer Value by Decision Tree Model.” Expert Systems with Applications, 2012, https://doi.org/10.1016/j.eswa.2011.09.034. 

[9] “Data Mining Techniques for Segmentation.” Data Mining Techniques in CRM, pp. 65–132, https://doi.org/10.1002/9780470685815.ch3. 

[10] Bayer, Judy. “Customer Segmentation in the Telecommunications Industry.” Journal of Database Marketing &amp;amp; Customer Strategy Management, 2010, https://doi.org/10.1057/dbm.2010.21. 

[11] Kanchanapoom, Kessara, and Jongsawas Chongwatpol. “Integrated Customer Lifetime Value (CLV) and Customer Migration Model to Improve Customer Segmentation.” Journal of Marketing Analytics, 2022, https://doi.org/10.1057/s41270-022-00158-7. 

[12] Cheng, Guang Hua. “A Collaborative Filtering Recommendation Algorithm Based on User Clustering in E-Commerce Personalized Systems.” Advanced Materials Research, 2011, https://doi.org/10.4028/www.scientific.net/amr.267.789. 


[23] Michael Colins. 2017. Machine Learning: An Introduction to Supervised and Unsupervised Learning Algorithms.

[24] Chirag Shah. 2020. A Hands-On Introduction to Data Science. Cambridge University Press.

[25] Sunil Kumar Chinnamgari. 2019. R Machine Learning Projects: Implement supervised, unsupervised, and reinforcement learning techniques using R 3.5. Packt Publishing Ltd.

[27] Kevin Jolly. 2018. Machine Learning with scikit-learn Quick Start Guide: Classification, regression, and clustering techniques in Python. Packt Publishing Ltd.











